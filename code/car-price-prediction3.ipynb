{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment3 Car Price Prediction (Cont.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "import warnings\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import classification_report\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Cars.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>year</th>\n",
       "      <th>selling_price</th>\n",
       "      <th>km_driven</th>\n",
       "      <th>fuel</th>\n",
       "      <th>seller_type</th>\n",
       "      <th>transmission</th>\n",
       "      <th>owner</th>\n",
       "      <th>mileage</th>\n",
       "      <th>engine</th>\n",
       "      <th>max_power</th>\n",
       "      <th>torque</th>\n",
       "      <th>seats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Maruti Swift Dzire VDI</td>\n",
       "      <td>2014</td>\n",
       "      <td>450000</td>\n",
       "      <td>145500</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>First Owner</td>\n",
       "      <td>23.4 kmpl</td>\n",
       "      <td>1248 CC</td>\n",
       "      <td>74 bhp</td>\n",
       "      <td>190Nm@ 2000rpm</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Skoda Rapid 1.5 TDI Ambition</td>\n",
       "      <td>2014</td>\n",
       "      <td>370000</td>\n",
       "      <td>120000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>Second Owner</td>\n",
       "      <td>21.14 kmpl</td>\n",
       "      <td>1498 CC</td>\n",
       "      <td>103.52 bhp</td>\n",
       "      <td>250Nm@ 1500-2500rpm</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honda City 2017-2020 EXi</td>\n",
       "      <td>2006</td>\n",
       "      <td>158000</td>\n",
       "      <td>140000</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>Third Owner</td>\n",
       "      <td>17.7 kmpl</td>\n",
       "      <td>1497 CC</td>\n",
       "      <td>78 bhp</td>\n",
       "      <td>12.7@ 2,700(kgm@ rpm)</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hyundai i20 Sportz Diesel</td>\n",
       "      <td>2010</td>\n",
       "      <td>225000</td>\n",
       "      <td>127000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>First Owner</td>\n",
       "      <td>23.0 kmpl</td>\n",
       "      <td>1396 CC</td>\n",
       "      <td>90 bhp</td>\n",
       "      <td>22.4 kgm at 1750-2750rpm</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Maruti Swift VXI BSIII</td>\n",
       "      <td>2007</td>\n",
       "      <td>130000</td>\n",
       "      <td>120000</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>First Owner</td>\n",
       "      <td>16.1 kmpl</td>\n",
       "      <td>1298 CC</td>\n",
       "      <td>88.2 bhp</td>\n",
       "      <td>11.5@ 4,500(kgm@ rpm)</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           name  year  selling_price  km_driven    fuel  \\\n",
       "0        Maruti Swift Dzire VDI  2014         450000     145500  Diesel   \n",
       "1  Skoda Rapid 1.5 TDI Ambition  2014         370000     120000  Diesel   \n",
       "2      Honda City 2017-2020 EXi  2006         158000     140000  Petrol   \n",
       "3     Hyundai i20 Sportz Diesel  2010         225000     127000  Diesel   \n",
       "4        Maruti Swift VXI BSIII  2007         130000     120000  Petrol   \n",
       "\n",
       "  seller_type transmission         owner     mileage   engine   max_power  \\\n",
       "0  Individual       Manual   First Owner   23.4 kmpl  1248 CC      74 bhp   \n",
       "1  Individual       Manual  Second Owner  21.14 kmpl  1498 CC  103.52 bhp   \n",
       "2  Individual       Manual   Third Owner   17.7 kmpl  1497 CC      78 bhp   \n",
       "3  Individual       Manual   First Owner   23.0 kmpl  1396 CC      90 bhp   \n",
       "4  Individual       Manual   First Owner   16.1 kmpl  1298 CC    88.2 bhp   \n",
       "\n",
       "                     torque  seats  \n",
       "0            190Nm@ 2000rpm    5.0  \n",
       "1       250Nm@ 1500-2500rpm    5.0  \n",
       "2     12.7@ 2,700(kgm@ rpm)    5.0  \n",
       "3  22.4 kgm at 1750-2750rpm    5.0  \n",
       "4     11.5@ 4,500(kgm@ rpm)    5.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show the table\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8128, 13)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the shape of your data\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It means this table consist of 8128 samples, and 12 features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I rearranged data according to requiements of Chaky's Company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For the feature owner, map First Owner to 1, ..., Test Drive Car to 5\n",
    "\n",
    "# Using Dictionary for mapping\n",
    "dict_map = {'First Owner': 1,\n",
    "    'Second Owner': 2, 'Third Owner' :3, 'Fourth & Above Owner' :4, 'Test Drive Car':5}\n",
    "updateOwner = df['owner'].map(dict_map)\n",
    "df['owner'] = updateOwner\n",
    "\n",
    "#For the feature fuel, remove all rows with CNG and LPG\n",
    "df = df[df[\"fuel\"].str.contains(\"CNG|LPG\") == False]\n",
    "\n",
    "#For the featurre mileage, remove \"kmpl\" and convert the column to float\n",
    "df['mileage'] = df['mileage'].str.replace('kmpl', '').astype(float)\n",
    "\n",
    "#For the feature engine, remove \"CC\" and convert the column to float\n",
    "df['engine'] = df['engine'].str.replace('CC', '').astype(float)\n",
    "\n",
    "#For the feature max power, remove \"bhp\" and convert the column to float\n",
    "df['max_power'] = df['max_power'].str.replace('bhp', '').astype(float)\n",
    "\n",
    "#For the feature brand, take only the first word and remove the rest\n",
    "updateBrand = df['name'].str.split().str.get(0)\n",
    "df['name'] = updateBrand\n",
    "\n",
    "#Drop the feature torque since Chaky's company does not understand the kind of information\n",
    "df =df.drop(columns=[\"torque\"])\n",
    "\n",
    "#Delete all sample related to Test Drive Cars because they are too expensive so that Chaky's company doesn't interested\n",
    "df = df.loc[df[\"owner\"] != 5 ]\n",
    "\n",
    "#list unique values in the column fuel, and the data contains of 2 types of fuel which are Dissel and Petrol\n",
    "df['fuel'].unique()\n",
    "\n",
    "#convert categorical type of features in to numerical \n",
    "#use label encoding to covert fuel types to numbers\n",
    "le = LabelEncoder()\n",
    "df['fuel'] = le.fit_transform(df['fuel'])\n",
    "df['fuel'] = le.fit_transform(df['fuel'])\n",
    "\n",
    "#list unique values in the column seller_type, and the data contains of 3 types of sellers which are Individual, Dealer, and Trutmark Dealer\n",
    "df['seller_type'].unique()\n",
    "\n",
    "#use label encoding to covert seller types to numbers\n",
    "df['seller_type'] = le.fit_transform(df['seller_type'])\n",
    "df['seller_type'] = le.fit_transform(df['seller_type'])\n",
    "\n",
    "#list unique values in the column transmission, and the data contains of 2 types of transmission which are Munual, and Automatic\n",
    "df['transmission'].unique()\n",
    "\n",
    "#use label encoding to covert transmission categories to numbers\n",
    "df['transmission'] = le.fit_transform(df['transmission'])\n",
    "df['transmission'] = le.fit_transform(df['transmission'])\n",
    "\n",
    "#use label encoding to covert brands to numbers\n",
    "df['name'] = le.fit_transform(df['name'])\n",
    "df['name'] = le.fit_transform(df['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    8.028000e+03\n",
       "mean     6.403937e+05\n",
       "std      8.027015e+05\n",
       "min      2.999900e+04\n",
       "25%      2.600000e+05\n",
       "50%      4.500000e+05\n",
       "75%      6.800000e+05\n",
       "max      1.000000e+07\n",
       "Name: selling_price, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show statistical information of selling_price column\n",
    "df['selling_price'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the label selling price into discrete variable by simply putting the price in a bucket of 0, 1, 2, 3\n",
    "df['selling_price'] = pd.cut(x=df['selling_price'], bins=[29998, 260000, 450000, 680000, 10000000],\n",
    "labels=['0', '1', '2','3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2050\n",
       "1    2044\n",
       "3    1991\n",
       "2    1943\n",
       "Name: selling_price, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show number of samples in each categories\n",
    "df['selling_price'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>year</th>\n",
       "      <th>selling_price</th>\n",
       "      <th>km_driven</th>\n",
       "      <th>fuel</th>\n",
       "      <th>seller_type</th>\n",
       "      <th>transmission</th>\n",
       "      <th>owner</th>\n",
       "      <th>mileage</th>\n",
       "      <th>engine</th>\n",
       "      <th>max_power</th>\n",
       "      <th>seats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>145500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23.40</td>\n",
       "      <td>1248.0</td>\n",
       "      <td>74.00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>120000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>21.14</td>\n",
       "      <td>1498.0</td>\n",
       "      <td>103.52</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>2006</td>\n",
       "      <td>0</td>\n",
       "      <td>140000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>17.70</td>\n",
       "      <td>1497.0</td>\n",
       "      <td>78.00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>127000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23.00</td>\n",
       "      <td>1396.0</td>\n",
       "      <td>90.00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "      <td>120000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16.10</td>\n",
       "      <td>1298.0</td>\n",
       "      <td>88.20</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8123</th>\n",
       "      <td>11</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>110000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18.50</td>\n",
       "      <td>1197.0</td>\n",
       "      <td>82.85</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8124</th>\n",
       "      <td>11</td>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "      <td>119000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>16.80</td>\n",
       "      <td>1493.0</td>\n",
       "      <td>110.00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8125</th>\n",
       "      <td>20</td>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>120000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.30</td>\n",
       "      <td>1248.0</td>\n",
       "      <td>73.90</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8126</th>\n",
       "      <td>28</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>25000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23.57</td>\n",
       "      <td>1396.0</td>\n",
       "      <td>70.00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8127</th>\n",
       "      <td>28</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>25000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23.57</td>\n",
       "      <td>1396.0</td>\n",
       "      <td>70.00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8028 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      name  year selling_price  km_driven  fuel  seller_type  transmission  \\\n",
       "0       20  2014             1     145500     0            1             1   \n",
       "1       27  2014             1     120000     0            1             1   \n",
       "2       10  2006             0     140000     1            1             1   \n",
       "3       11  2010             0     127000     0            1             1   \n",
       "4       20  2007             0     120000     1            1             1   \n",
       "...    ...   ...           ...        ...   ...          ...           ...   \n",
       "8123    11  2013             1     110000     1            1             1   \n",
       "8124    11  2007             0     119000     0            1             1   \n",
       "8125    20  2009             1     120000     0            1             1   \n",
       "8126    28  2013             1      25000     0            1             1   \n",
       "8127    28  2013             1      25000     0            1             1   \n",
       "\n",
       "      owner  mileage  engine  max_power  seats  \n",
       "0         1    23.40  1248.0      74.00    5.0  \n",
       "1         2    21.14  1498.0     103.52    5.0  \n",
       "2         3    17.70  1497.0      78.00    5.0  \n",
       "3         1    23.00  1396.0      90.00    5.0  \n",
       "4         1    16.10  1298.0      88.20    5.0  \n",
       "...     ...      ...     ...        ...    ...  \n",
       "8123      1    18.50  1197.0      82.85    5.0  \n",
       "8124      4    16.80  1493.0     110.00    5.0  \n",
       "8125      1    19.30  1248.0      73.90    5.0  \n",
       "8126      1    23.57  1396.0      70.00    5.0  \n",
       "8127      1    23.57  1396.0      70.00    5.0  \n",
       "\n",
       "[8028 rows x 12 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform selling price using log transform because big number can cause prediction to be unstable\n",
    "#df['selling_price'] = np.log(df[\"selling_price\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert selling price categories into int type\n",
    "df['selling_price'] = df['selling_price'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x is our strong features\n",
    "X = df[['max_power', 'mileage',  'year']]\n",
    "\n",
    "#y is selling price column which I would like to predict\n",
    "y = df[\"selling_price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into train and test set with ratio 70:30, and choose random state = 42\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)\n",
    "\n",
    "# convert into array\n",
    "y_train = y_train.to_numpy()\n",
    "y_test = y_test.to_numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "max_power    149\n",
       "mileage      154\n",
       "year           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for null values for X_train\n",
    "X_train[['max_power', 'mileage',  'year']].isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "max_power    59\n",
       "mileage      60\n",
       "year          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for null values for X_test\n",
    "X_test[['max_power', 'mileage',  'year']].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill the training set \n",
    "\n",
    "X_train['max_power'].fillna(X_train['max_power'].median(), inplace=True)\n",
    "X_train['mileage'].fillna(X_train['mileage'].mean(), inplace=True)\n",
    "\n",
    "#fill the testing set with the training distribution \n",
    "\n",
    "X_test['max_power'].fillna(X_train['max_power'].median(), inplace=True)\n",
    "X_test['mileage'].fillna(X_train['mileage'].mean(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "max_power    0\n",
       "mileage      0\n",
       "year         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check null values to make sure that there is no null values left\n",
    "X_train[['max_power', 'mileage', 'year']].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "max_power    0\n",
       "mileage      0\n",
       "year         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check null values to make sure that there is no null values left\n",
    "X_test[['max_power', 'mileage', 'year']].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train[['year','mileage','max_power']] = scaler.fit_transform(X_train[['year','mileage','max_power']])\n",
    "X_test[['year','mileage','max_power']]  = scaler.transform(X_test[['year','mileage','max_power']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the experiment, I will perform using MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#experiment tracking\n",
    "import mlflow\n",
    "import os\n",
    "# This the dockerized method.\n",
    "# We build two docker containers, one for python/jupyter and another for mlflow.\n",
    "# The url `mlflow` is resolved into another container within the same composer.\n",
    "mlflow.set_tracking_uri(\"https://mlflow.cs.ait.ac.th/\")\n",
    "# In the dockerized way, the user who runs this code will be `root`.\n",
    "# The MLflow will also log the run user_id as `root`.\n",
    "# To change that, we need to set this environ[\"LOGNAME\"] to your name.\n",
    "os.environ[\"LOGNAME\"] = \"thamakorn\"\n",
    "#mlflow.create_experiment(name=\"a3_assignment\")  #create if you haven't create\n",
    "mlflow.set_experiment(experiment_name=\"st124481-a3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "intercept = np.ones((X_train.shape[0], 1))\n",
    "X_train   = np.concatenate((intercept, X_train), axis=1)\n",
    "intercept = np.ones((X_test.shape[0], 1))\n",
    "X_test    = np.concatenate((intercept, X_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = len(set(y))  # no. of class  \n",
    "m = X_train.shape[0]  # no.of samples\n",
    "n = X_train.shape[1]  # no. of features\n",
    "Y_train_encoded = np.zeros((m, k))\n",
    "for each_class in range(k):\n",
    "    cond = y_train==each_class\n",
    "    Y_train_encoded[np.where(cond), each_class] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "class LogisticRegression:\n",
    "\n",
    "    kfold = KFold(n_splits=3)\n",
    "    \n",
    "    def __init__(self,regulaization, k, n, method, alpha = 0.001, max_iter=5000, cv=kfold):\n",
    "        self.regularization = regulaization\n",
    "        self.k = k\n",
    "        self.n = n\n",
    "        self.alpha = alpha\n",
    "        self.max_iter = max_iter\n",
    "        self.method = method\n",
    "        self.cv =cv\n",
    "\n",
    "    #loss validation\n",
    "    def loss_val(self, X, y):\n",
    "        m = y.shape[0]\n",
    "        h = self.h_theta(X, self.W)\n",
    "        loss = - np.sum(y*np.log(h)) / m\n",
    "        return loss\n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        self.val_losses = []\n",
    "        for fold, (train_idx, val_idx) in enumerate(self.cv.split(X)):\n",
    "            print(\"=\"*5,f\"Fold{fold}\",\"=\"*5)\n",
    "            X_cross_train = X[train_idx]\n",
    "            y_cross_train = Y[train_idx]\n",
    "            X_cross_val   = X[val_idx]\n",
    "            y_cross_val   = Y[val_idx]\n",
    "            \n",
    "            self.W = np.random.rand(self.n, self.k)\n",
    "            self.losses = []\n",
    "\n",
    "\n",
    "          #one epoch will exhaust the WHOLE training set\n",
    "            with mlflow.start_run(run_name=f\"Fold-{fold}\", nested=True):            \n",
    "                params = {\"reg\": type(self).__name__, \"method\": self.method, \"lr\": self.alpha, \"max_iter\": self.max_iter}\n",
    "                mlflow.log_params(params=params)\n",
    "                if self.method == \"batch\":\n",
    "                    start_time = time.time()\n",
    "                    for i in range(self.max_iter):\n",
    "                        loss, grad =  self.gradient(X_cross_train, y_cross_train)\n",
    "                        self.losses.append(loss)\n",
    "                        self.W = self.W - self.alpha * grad\n",
    "                        val_loss = self.loss_val(X_cross_val, y_cross_val)\n",
    "                        if i % 1000 == 0:\n",
    "                            print(f\"Train Loss at iteration {i}\", loss, end=\",\")\n",
    "                            print(f\"Val Loss at iteration {i}\", val_loss)\n",
    "                    print(f\"time taken: {time.time() - start_time}\")\n",
    "                    \n",
    "                elif self.method == \"minibatch\":\n",
    "                    start_time = time.time()\n",
    "                    batch_size = int(0.3 * X.shape[0])\n",
    "                    for i in range(self.max_iter):\n",
    "                        ix = np.random.randint(0, X.shape[0]) #<----with replacement\n",
    "                        batch_X = X[ix:ix+batch_size]\n",
    "                        batch_Y = Y[ix:ix+batch_size]\n",
    "                        loss, grad = self.gradient(batch_X, batch_Y)\n",
    "                        self.losses.append(loss)\n",
    "                        self.W = self.W - self.alpha * grad\n",
    "                        val_loss= self.loss_val(X_cross_val, y_cross_val)\n",
    "                        if i % 1000 == 0:\n",
    "                            print(f\"Train Loss at iteration {i}\", loss, end=\",\")\n",
    "                            print(f\"Val Loss at iteration {i}\", val_loss)\n",
    "                    print(f\"time taken: {time.time() - start_time}\")\n",
    "                    \n",
    "                elif self.method == \"sto\":\n",
    "                    start_time = time.time()\n",
    "                    list_of_used_ix = []\n",
    "                    for i in range(self.max_iter):\n",
    "                        idx = np.random.randint(X.shape[0])\n",
    "                        while i in list_of_used_ix:\n",
    "                            idx = np.random.randint(X.shape[0])\n",
    "                        X_train = X[idx, :].reshape(1, -1)\n",
    "                        Y_train = Y[idx]\n",
    "                        loss, grad = self.gradient(X_train, Y_train)\n",
    "                        self.losses.append(loss)\n",
    "                        self.W = self.W - self.alpha * grad\n",
    "                        val_loss= self.loss_val(X_cross_val, y_cross_val)\n",
    "                        list_of_used_ix.append(i)\n",
    "                        if len(list_of_used_ix) == X.shape[0]:\n",
    "                            list_of_used_ix = []\n",
    "                        if i % 1000 == 0:\n",
    "                            print(f\"Train Loss at iteration {i}\", loss, end=\",\")\n",
    "                            print(f\"Val Loss at iteration {i}\", val_loss)\n",
    "                    print(f\"time taken: {time.time() - start_time}\")\n",
    "                    \n",
    "                else:\n",
    "                    raise ValueError('Method must be one of the followings: \"batch\", \"minibatch\" or \"sto\".')\n",
    "            self.val_losses.append(val_loss)\n",
    "        # log the average of validation loss of 3 fold on MLflow\n",
    "        mlflow.log_metric(key=\"avg val_loss\", value=sum(self.val_losses) / len(self.val_losses))\n",
    "        print(\"Mean of val_loss of 3 fold: \",sum(self.val_losses) / len(self.val_losses) )\n",
    "        params = {\"reg\": type(self).__name__,\"method\": self.method, \"lr\": self.alpha, \"max_iter\": self.max_iter}\n",
    "        mlflow.log_params(params=params)\n",
    " \n",
    "        \n",
    "        \n",
    "    def gradient(self, X, Y):\n",
    "        m = X.shape[0]\n",
    "        h = self.h_theta(X, self.W)\n",
    "        loss = - np.sum(Y*np.log(h)) / m\n",
    "        error = h - Y\n",
    "        grad = self.softmax_grad(X, error)+ self.regularization.derivation(self.W)\n",
    "        return loss, grad\n",
    "\n",
    "    def softmax(self, theta_t_x):\n",
    "        return np.exp(theta_t_x) / np.sum(np.exp(theta_t_x), axis=1, keepdims=True)\n",
    "\n",
    "    def softmax_grad(self, X, error):\n",
    "        return  X.T @ error\n",
    "\n",
    "    def h_theta(self, X, W):\n",
    "        '''\n",
    "        Input:\n",
    "            X shape: (m, n)\n",
    "            w shape: (n, k)\n",
    "        Returns:\n",
    "            yhat shape: (m, k)\n",
    "        '''\n",
    "        return self.softmax(X @ W)\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        return np.argmax(self.h_theta(X_test, self.W), axis=1)\n",
    "    \n",
    "    def plot(self):\n",
    "        plt.plot(np.arange(len(self.losses)) , self.losses, label = \"Train Losses\")\n",
    "        plt.title(\"Losses\")\n",
    "        plt.xlabel(\"epoch\")\n",
    "        plt.ylabel(\"losses\")\n",
    "        plt.legend()\n",
    "\n",
    "    #create a function that calculate accuracy\n",
    "    def accuracy(self, X_test, y_test):\n",
    "\n",
    "        y_pred = self.predict(X_test)\n",
    "        true_predict = 0\n",
    "        for i in range(len(y_test)):\n",
    "            if (y_test[i] == y_pred[i]):\n",
    "                true_predict +=1\n",
    "            else:\n",
    "                true_predict += 0\n",
    "        accuracy = true_predict/ len(y_test)\n",
    "        return accuracy\n",
    "    \n",
    "    #create a function that calculate precision\n",
    "    def precision(self, X_test, y_test, class_label):\n",
    "        y_pred = self.predict(X_test)\n",
    "    \n",
    "        true_positives = sum(1 for i in range(len(y_test)) if y_test[i] == class_label and y_pred[i] == class_label)\n",
    "        predicted_positives = sum(1 for i in range(len(y_test)) if y_pred[i] == class_label)\n",
    "    \n",
    "        if predicted_positives == 0:\n",
    "            return 0  #  avoid division by zero.\n",
    "    \n",
    "        precision = true_positives / predicted_positives\n",
    "        return precision\n",
    "    \n",
    "    #create a function that calculate recall\n",
    "    def recall(self, X_test, y_test, class_label):\n",
    "        y_pred = self.predict(X_test)\n",
    "    \n",
    "        true_positive = sum(1 for i in range(len(y_test)) if y_test[i] == class_label and y_pred[i] == class_label)\n",
    "        false_negative = sum(1 for i in range(len(y_test)) if y_test[i] == class_label and y_pred[i] != class_label)\n",
    "    \n",
    "        if true_positive + false_negative == 0:\n",
    "            return 0  \n",
    "    \n",
    "        recall = true_positive / (true_positive + false_negative)\n",
    "        return recall\n",
    "    \n",
    "    #create a function that calculate f1\n",
    "    def f1(self, precision, recall, class_label):\n",
    "        precision = self.precision(X_test, y_test, class_label)\n",
    "        recall = self.recall(X_test, y_test, class_label)\n",
    "\n",
    "        if precision + recall == 0:\n",
    "            return 0  \n",
    "\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "        return f1_score\n",
    "    \n",
    "    #create a function that calculate macro precision\n",
    "    def macro_precision(self):\n",
    "        class_labels = np.unique(y_test)\n",
    "        total_precision = 0.0\n",
    "\n",
    "        for label in class_labels:\n",
    "            precision = self.precision(X_test, y_test, class_label=label)\n",
    "            total_precision += precision\n",
    "\n",
    "        macro_precision = total_precision / len(class_labels)\n",
    "        return macro_precision\n",
    "    \n",
    "    #create a function that calculate macro recall\n",
    "    def macro_recall(self):\n",
    "        class_labels = np.unique(y_test)\n",
    "        total_recall = 0.0\n",
    "\n",
    "        for label in class_labels:\n",
    "            recall = self.recall(X_test, y_test, class_label=label)\n",
    "            total_recall += recall\n",
    "\n",
    "        macro_recall = total_recall / len(class_labels)\n",
    "        return macro_recall\n",
    "    \n",
    "    #create a function that calculate macro f1\n",
    "    def macro_f1(self):\n",
    "        class_labels = np.unique(y_test)\n",
    "        total_f1 = 0.0\n",
    "\n",
    "        for label in class_labels:\n",
    "            f1 = self.f1(X_test, y_test, class_label=label)\n",
    "            total_f1 += f1\n",
    "\n",
    "        macro_f1 = total_f1 / len(class_labels)\n",
    "        return macro_f1\n",
    "    \n",
    "    #create a function that calculate weighted precision\n",
    "    def weighted_precision(self, X_test, y_test, class_weights):\n",
    "        class_labels = np.unique(y_test)\n",
    "        weighted_precision_sum = 0.0\n",
    "        total_weight = 0.0\n",
    "\n",
    "        for label in class_labels:\n",
    "            precision = self.precision(X_test, y_test, class_label=label)\n",
    "            class_weight = class_weights[label]\n",
    "            weighted_precision_sum += precision * class_weight\n",
    "            total_weight += class_weight\n",
    "\n",
    "        weighted_precision = weighted_precision_sum / total_weight\n",
    "        return weighted_precision\n",
    "    \n",
    "    #create a function that calculate weighted recall\n",
    "    def weighted_recall(self, X_test, y_test, class_weights):\n",
    "        class_labels = np.unique(y_test)\n",
    "        weighted_recall_sum = 0.0\n",
    "        total_weight = 0.0\n",
    "\n",
    "        for label in class_labels:\n",
    "            recall = self.recall(X_test, y_test, class_label=label)\n",
    "            class_weight = class_weights[label]\n",
    "            weighted_recall_sum += recall * class_weight\n",
    "            total_weight += class_weight\n",
    "\n",
    "        weighted_recall = weighted_recall_sum / total_weight\n",
    "        return weighted_recall\n",
    "    \n",
    "    #create a function that calculate weighted f1\n",
    "    def weighted_f1(self, X_test, y_test, class_weights):\n",
    "        class_labels = np.unique(y_test)\n",
    "        weighted_f1_sum = 0.0\n",
    "        total_weight = 0.0\n",
    "\n",
    "        for label in class_labels:\n",
    "            f1 = self.f1(X_test, y_test, class_label=label)\n",
    "            class_weight = class_weights[label]\n",
    "            weighted_f1_sum += f1 * class_weight\n",
    "            total_weight += class_weight\n",
    "\n",
    "        weighted_f1 = weighted_f1_sum / total_weight\n",
    "        return weighted_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function for looping classnames\n",
    "import sys\n",
    "\n",
    "def str_to_class(classname):\n",
    "    return getattr(sys.modules[__name__], classname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RidgePenalty:\n",
    "    \n",
    "    def __init__(self, l):\n",
    "        self.l = l\n",
    "        \n",
    "    def __call__(self, W): #__call__ allows us to call class as method\n",
    "        return self.l * np.sum(np.square(W))\n",
    "        \n",
    "    def derivation(self, W):\n",
    "        return self.l * 2 * W\n",
    "\n",
    "class NormalPenalty:\n",
    "\n",
    "    def __init__(self, l):\n",
    "        self.l = l\n",
    "        \n",
    "    def __call__(self, W): #__call__ allows us to call class as method\n",
    "        return 0\n",
    "        \n",
    "    def derivation(self, W):\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "        \n",
    "class Ridge(LogisticRegression):\n",
    "    \n",
    "    def __init__(self, k,n, method, alpha, l):\n",
    "        self.regularization = RidgePenalty(l)\n",
    "        super().__init__(self.regularization,k, n, method, alpha)\n",
    "\n",
    "class Normal(LogisticRegression):\n",
    "    \n",
    "    def __init__(self, k,n, method,alpha, l):\n",
    "        self.regularization = NormalPenalty(l)\n",
    "        super().__init__(self.regularization,k,n, method, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "regs = [\"Ridge\", \"Normal\"]\n",
    "methods = [\"sto\",\"minibatch\", \"batch\"]\n",
    "\n",
    "for reg in regs:\n",
    "    for method in methods:\n",
    "        params = {\"k\": k, \"n\": n, \"method\": method, \"alpha\": 0.0001, \"l\": 0.1}\n",
    "        # mlflow.start_run(run_name=f\"method-{params['method']}-reg-{reg}-lr-{params['alpha']}-l-{params['l']}\", nested=True)\n",
    "        print(\"=\"*5, reg,method,\"lr\",0.0001,\"l\",0.1, \"=\"*5)\n",
    "\n",
    "        # #######\n",
    "        type_of_regression = str_to_class(reg)    #Ridge, Normal\n",
    "        model = type_of_regression(**params)  \n",
    "        model.fit(X_train, Y_train_encoded)\n",
    "      \n",
    "\n",
    "        # signature = mlflow.models.infer_signature(X_train, model.predict(X_train))\n",
    "        # mlflow.sklearn.log_model(model, artifact_path='model', signature=signature)\n",
    "\n",
    "        # # #######\n",
    "\n",
    "        # mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(k, X_train.shape[1], \"batch\")\n",
    "model.fit(X_train, Y_train_encoded)\n",
    "yhat = model.predict(X_test)\n",
    "#model.plot()\n",
    "print(\"=========Classification report=======\")\n",
    "print(\"Report: \", classification_report(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_label = [0,1,2,3]\n",
    "class_weights = [0.2, 0.3, 0.2, 0.3]\n",
    "print(f\"accuracy: {model.accuracy(X_test, y_test)}\")\n",
    "for i in class_label:\n",
    "    print(\"-\"*10)\n",
    "    print(f\"precision for class %d: {model.precision(X_test, y_test, class_label=i)}\" %i)\n",
    "    print(f\"recall for class %d: {model.recall(X_test, y_test, class_label=i)}\" %i)\n",
    "    print(f\"f1 for class %d: {model.f1(X_test, y_test, class_label=i)}\" %i)\n",
    "print(\"-\"*10)\n",
    "print(f\"macro average precision: {model.macro_precision()}\" )\n",
    "print(f\"macro average recall: {model.macro_recall()}\" )\n",
    "print(f\"macro average f1: {model.macro_f1()}\" )\n",
    "print(\"-\"*10)\n",
    "print(f\"macro weighted precision: {model.weighted_precision(X_test, y_test, class_weights)}\" )\n",
    "print(f\"macro weighted recall: {model.weighted_recall(X_test, y_test, class_weights)}\" )\n",
    "print(f\"macro weighted f1: {model.weighted_f1(X_test, y_test, class_weights)}\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification report from scratch gives almost the same values of classification report of sk-learn library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RidgePenalty:\n",
    "    \n",
    "    def __init__(self, l):\n",
    "        self.l = l\n",
    "        \n",
    "    def __call__(self, theta): #__call__ allows us to call class as method\n",
    "        return self.l * np.sum(np.square(theta))\n",
    "        \n",
    "    def derivation(self, theta):\n",
    "        return self.l * 2 * theta\n",
    "\n",
    "\n",
    "class Ridge(LogisticRegression):\n",
    "    \n",
    "    def __init__(self, method,initweight,momentum, lr, l):\n",
    "        self.regularization = RidgePenalty(l)\n",
    "        super().__init__(self.regularization,lr, method,initweight,momentum)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function for looping classnames\n",
    "import sys\n",
    "\n",
    "def str_to_class(classname):\n",
    "    return getattr(sys.modules[__name__], classname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "# regs = [\"Ridge\", \"Lasso\", \"Normal\"]\n",
    "methods = [\"sto\",\"mini\", \"batch\"]\n",
    "# for reg in regs:\n",
    "for method in methods:\n",
    "    params = {\"method\": method, \"l\": 0.1}\n",
    "    mlflow.start_run(run_name=f\"method-{params['method']}-theta-{params['initweight']}-momentum-{params['momentum']}-lr-{params['lr']}-reg-{reg}\", nested=True)\n",
    "    \n",
    "    print(\"=\"*5, reg,method,theta,lr,\"=\"*5)\n",
    "\n",
    "    # #######\n",
    "    type_of_regression = str_to_class(reg)    #Ridge, Lasso, Normal\n",
    "    model = type_of_regression(**params)  \n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    signature = mlflow.models.infer_signature(X_train, model.predict(X_train))\n",
    "    mlflow.sklearn.log_model(model, artifact_path='model', signature=signature)\n",
    "\n",
    "    # #######\n",
    "\n",
    "    mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After I obtain the best model, I test performance of the model with test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mlflow.pyfunc.load_model('runs:/c9d107e58e6a4c13ba6749dcda021f02/model/')\n",
    "\n",
    "yhat = model.predict(X_test)\n",
    "mse  = ((yhat - y_test) ** 2).sum() / y_test.shape[0]\n",
    "r2 = 1-(((yhat - y_test) ** 2).sum() / (((y_test.sum()/y_test.shape[0])- y_test) ** 2).sum())\n",
    "\n",
    "\n",
    "print(\"Test MSE: \", mse)\n",
    "print(\"Test R2: \", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis:  Feature Importance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance(theta):\n",
    "        coefs = pd.DataFrame(\n",
    "        theta, columns=[\"Coefficients\"], index=['max_power', 'mileage',  'year']\n",
    "        )\n",
    "\n",
    "        coefs.plot(kind=\"barh\", figsize=(9, 7))\n",
    "        plt.title(\"Feature Importance\")\n",
    "        plt.axvline(x=0, color=\".5\")\n",
    "        plt.subplots_adjust(left=0.3)\n",
    "\n",
    "        \n",
    "run = mlflow.get_run(run_id=\"c9d107e58e6a4c13ba6749dcda021f02\")\n",
    "thetas = list()\n",
    "\n",
    "for i in range(X_train.shape[1]-1):\n",
    "        thetas.append(run.data.metrics[f'weight-{i}'])\n",
    "feature_importance(thetas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
